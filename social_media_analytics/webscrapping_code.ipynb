{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the information from https://euvsdisinfo.eu/disinformation-cases/ website"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data analysis and media monitoring services in multiple languages, EUvsDisinfo identifies, compiles, and exposes disinformation cases originating in pro-Kremlin outlets. These cases (and their disproofs) are collected in the EUvsDisinfo database â€“ the only searchable, open-source repository of its kind. The database is updated every week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "title_set = set()  # only unique titles\n",
    "page = 10  # first 10 articles\n",
    "add_page = True\n",
    "\n",
    "while add_page == True:\n",
    "    url = f'https://euvsdisinfo.eu/disinformation-cases/?text=&date=&orderby=date&offset={page}&per_page=10'\n",
    "    user_agents_list = [\n",
    "        'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
    "    ]\n",
    "\n",
    "    response = requests.get(url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: Failed to retrieve page for url {url}. Status code: {response.status_code}\")\n",
    "        continue\n",
    "\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    hits_all = soup.select('tbody')\n",
    "    rows = soup.find_all('tr', class_='disinfo-db-post')\n",
    "\n",
    "    for row in rows:\n",
    "        date = row.find('td', class_='disinfo-db-date').get_text(strip=True)\n",
    "        title = row.find('td', class_='cell-title').a.get_text(strip=True)\n",
    "\n",
    "        if title not in title_set:\n",
    "            article_url = 'https://euvsdisinfo.eu' + row.find('td', class_='cell-title').a['href']\n",
    "            outlet = row.find('div', class_='disinfo-outlets-list').get_text(strip=True)\n",
    "            country = row.find('td', class_='disinfo-db-cell cell-country').get_text(strip=True)\n",
    "\n",
    "            article_response = requests.get(article_url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "\n",
    "            if article_response.status_code == 200:\n",
    "                article_html = article_response.text\n",
    "                article_soup = BeautifulSoup(article_html, 'html.parser')\n",
    "                article_summary = '\\n'.join([p.text.strip() for p in article_soup.select('div.b-report__summary-text')])\n",
    "                article_disproof = '\\n'.join([p.text.strip() for p in article_soup.select('div.b-report__disproof-text')])\n",
    "                article_language = re.sub(r'^Article language\\(s\\)\\n\\s*', '','\\n'.join([p.text.strip() for p in article_soup.select('div.b-catalog__col2 > div > div > ul > li:nth-child(3)')])).strip()\n",
    "                article_keywords = re.sub(r'^Keywords:\\n', '', '\\n'.join([p.text.strip() for p in article_soup.select('div.b-catalog__col2 > div > div > ul > li:nth-child(5)')])).strip()\n",
    "\n",
    "            else:\n",
    "                print(f\"Error: Failed to retrieve page for url {article_html}. Status code: {response.status_code}\")\n",
    "                continue\n",
    "\n",
    "            results.append({\n",
    "                'Date': date,\n",
    "                'Title': title,\n",
    "                'URL': article_url,\n",
    "                'Outlets': outlet,\n",
    "                'Countries': country,\n",
    "                'Language': article_language,\n",
    "                'Summary': article_summary,\n",
    "                'Disproof': article_disproof,\n",
    "                'Keywords': article_keywords\n",
    "            })\n",
    "\n",
    "            title_set.add(title)\n",
    "            time.sleep(1)\n",
    "\n",
    "    if soup.select_one('div.reports_loadmore'):\n",
    "        page += 10\n",
    "    else:\n",
    "        add_page = False\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('disinformation_database.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took 5 hours to run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9965, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Outlets</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Language</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Disproof</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.05.2023</td>\n",
       "      <td>USSR Victory Banner was raised over the Bundes...</td>\n",
       "      <td>https://euvsdisinfo.eu/report/ussr-victory-ban...</td>\n",
       "      <td>ntv.ru,eadaily.com,Moskovskij Komsomolets,tsar...</td>\n",
       "      <td>Russia,                                       ...</td>\n",
       "      <td>Russian</td>\n",
       "      <td>The Russians took Berlin without firing a shot...</td>\n",
       "      <td>The video is a manipulation. The Red Banner of...</td>\n",
       "      <td>World War 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Title  \\\n",
       "0  10.05.2023  USSR Victory Banner was raised over the Bundes...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://euvsdisinfo.eu/report/ussr-victory-ban...   \n",
       "\n",
       "                                             Outlets  \\\n",
       "0  ntv.ru,eadaily.com,Moskovskij Komsomolets,tsar...   \n",
       "\n",
       "                                           Countries Language  \\\n",
       "0  Russia,                                       ...  Russian   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  The Russians took Berlin without firing a shot...   \n",
       "\n",
       "                                            Disproof     Keywords  \n",
       "0  The video is a manipulation. The Red Banner of...  World War 2  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9965 rows with fake news or dissinformation and 9 columns:\n",
    "* Date - the date of fake news release\n",
    "* Title - the title of the fake news\n",
    "* URL - web link to the news description\n",
    "* Outlets - news agences from dissinformation originated\n",
    "* Countries - countries mentioned in the fake news\n",
    "* Language - the language of the fake news\n",
    "* Summary - summary of the fake news\n",
    "* Disproof - points made by \"EU vs Disinfo\" organization to disproof the fake news\n",
    "* Keywords - keywords from the fake news"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMA-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
